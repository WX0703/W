#~MNIST数据集
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("MNISTdata/", one_hot=True)

#~实现softmax回归模型
import tensorflow as tf
#通过操作符号变量来描述可交互的操作单元
x = tf.placeholder("float", [None,784])
#对于各种机器学习应用，一般都会有模型参数，可以用Variable表示
#我们赋予tf.Variable不同的初值来创建不同的Variable：这里使用全为零的张量来初始化W和b
W = tf.Variable(tf.zeros([784,10]))
b = tf.Variable(tf.zeros([10]))
#实现模型
y = tf.nn.softmax(tf.matmul(x,W) + b)

#~训练模型
#为了计算交叉熵，需要添加一个新的占位符用于输入正确值
y_ = tf.placeholder("float",[None,10])
#计算交叉熵
cross_entropy = -tf.reduce_sum(y_*tf.log(y))
#TensorFlow会用选择的优化算法来不断修改变量以降低成本
train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)
#在运行计算之前，需要添加一个操作来初始化创建的变量
init = tf.initialize_all_variables()
#现在可以在一个Session里面启动模型，并且初始化变量
sess = tf.Session()
sess.run(init)
#开始训练模型（这里让模型循环训练1000次）
for i in range(1000):
    batch_xs,batch_ys = mnist.train.next_batch(100)
    sess.run(train_step,feed_dict = {x:batch_xs,y_:batch_ys})

#~评估模型
'''tf.argmax(y,1)返回的是模型对于任意输入x预测到的标签值，而tf.argmax(y_,1)
代表正确的标签，可以用tf.equal来检测预测是否正确'''
correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))
#可以得到一组布尔值，转换为浮点数之后取平均值可以得到正确率
accuracy = tf.reduce_mean(tf.cast(correct_prediction,"float"))
#最后，计算正确率
print(sess.run(accuracy,feed_dict = {x:mnist.test.images, y_:mnist.test.labels}))
